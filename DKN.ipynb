{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "laughing-amount",
   "metadata": {},
   "source": [
    "# DKN : Deep Knowledge-Aware Network for News Recommendation\n",
    "\n",
    "DKN [1] is a deep learning model which incorporates information from knowledge graph for better news recommendation. Specifically, DKN uses TransX [2] method for knowledge graph representation learning, then applies a CNN framework, named KCNN, to combine entity embedding with word embedding and generate a final embedding vector for a news article. CTR prediction is made via an attention-based neural scorer.\n",
    "\n",
    "## Properties of DKN:\n",
    "\n",
    "  - DKN is a content-based deep model for CTR prediction rather than traditional ID-based collaborative filtering.\n",
    "  - It makes use of knowledge entities and common sense in news content via joint learning from semantic-level and knowledge-level representations of news articles.\n",
    "  - DKN uses an attention module to dynamically calculate a user's aggregated historical representaition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beneficial-jason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.10 | packaged by conda-forge | (default, Feb 19 2021, 16:07:37) \n",
      "[GCC 9.3.0]\n",
      "Tensorflow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "#import scrapbook as sb\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources, prepare_hparams\n",
    "from recommenders.models.deeprec.models.dkn import DKN\n",
    "from recommenders.models.deeprec.io.dkn_iterator import DKNTextIterator\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-archive",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "activated-alert",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11.3k/11.3k [00:00<00:00, 26.8kKB/s]\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "data_path = os.path.join(cwd, \"mind-demo-dkn\")\n",
    "\n",
    "yaml_file = os.path.join(data_path, r'dkn.yaml')\n",
    "train_file = os.path.join(data_path, r'train_mind_demo.txt')\n",
    "valid_file = os.path.join(data_path, r'valid_mind_demo.txt')\n",
    "test_file = os.path.join(data_path, r'test_mind_demo.txt')\n",
    "news_feature_file = os.path.join(data_path, r'doc_feature.txt')\n",
    "user_history_file = os.path.join(data_path, r'user_history.txt')\n",
    "wordEmb_file = os.path.join(data_path, r'word_embeddings_100.npy')\n",
    "entityEmb_file = os.path.join(data_path, r'TransE_entity2vec_100.npy')\n",
    "contextEmb_file = os.path.join(data_path, r'TransE_context2vec_100.npy')\n",
    "\n",
    "if not os.path.exists(yaml_file):\n",
    "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/deeprec/', cwd, 'mind-demo-dkn.zip')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-trance",
   "metadata": {},
   "source": [
    "### Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "familiar-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history_size = 50\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "compliant-kruger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HParams object with values {'use_entity': True, 'use_context': True, 'cross_activation': 'identity', 'user_dropout': False, 'dropout': [0.0], 'attention_dropout': 0.0, 'load_saved_model': False, 'fast_CIN_d': 0, 'use_Linear_part': False, 'use_FM_part': False, 'use_CIN_part': False, 'use_DNN_part': False, 'init_method': 'uniform', 'init_value': 0.1, 'embed_l2': 1e-06, 'embed_l1': 0.0, 'layer_l2': 1e-06, 'layer_l1': 0.0, 'cross_l2': 0.0, 'cross_l1': 0.0, 'reg_kg': 0.0, 'learning_rate': 0.0005, 'lr_rs': 1, 'lr_kg': 0.5, 'kg_training_interval': 5, 'max_grad_norm': 2, 'is_clip_norm': 0, 'dtype': 32, 'optimizer': 'adam', 'epochs': 10, 'batch_size': 100, 'enable_BN': True, 'show_step': 10000, 'save_model': False, 'save_epoch': 2, 'write_tfevents': False, 'train_num_ngs': 4, 'need_sample': True, 'embedding_dropout': 0.0, 'EARLY_STOP': 100, 'min_seq_length': 1, 'slots': 5, 'cell': 'SUM', 'doc_size': 10, 'history_size': 50, 'word_size': 12600, 'entity_size': 3987, 'data_format': 'dkn', 'metrics': ['auc'], 'pairwise_metrics': ['group_auc', 'mean_mrr', 'ndcg@5;10'], 'method': 'classification', 'activation': ['sigmoid'], 'attention_activation': 'relu', 'attention_layer_sizes': 100, 'dim': 100, 'entity_dim': 100, 'transform': True, 'filter_sizes': [1, 2, 3], 'layer_sizes': [300], 'model_type': 'dkn', 'num_filters': 100, 'loss': 'log_loss', 'news_feature_file': '/ssd003/home/bjimenez/news_recommender/mind-demo-dkn/doc_feature.txt', 'user_history_file': '/ssd003/home/bjimenez/news_recommender/mind-demo-dkn/user_history.txt', 'wordEmb_file': '/ssd003/home/bjimenez/news_recommender/mind-demo-dkn/word_embeddings_100.npy', 'entityEmb_file': '/ssd003/home/bjimenez/news_recommender/mind-demo-dkn/TransE_entity2vec_100.npy', 'contextEmb_file': '/ssd003/home/bjimenez/news_recommender/mind-demo-dkn/TransE_context2vec_100.npy'}\n"
     ]
    }
   ],
   "source": [
    "hparams = prepare_hparams(yaml_file,\n",
    "                          news_feature_file = news_feature_file,\n",
    "                          user_history_file = user_history_file,\n",
    "                          wordEmb_file=wordEmb_file,\n",
    "                          entityEmb_file=entityEmb_file,\n",
    "                          contextEmb_file=contextEmb_file,\n",
    "                          epochs=epochs,\n",
    "                          history_size=history_size,\n",
    "                          batch_size=batch_size)\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "automatic-playback",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd003/projects/aieng/public/recsys/lib/python3.7/site-packages/recommenders/models/deeprec/models/dkn.py:309: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  training=self.is_train_stage,\n",
      "/ssd003/projects/aieng/public/recsys/lib/python3.7/site-packages/recommenders/models/deeprec/models/dkn.py:197: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  training=self.is_train_stage,\n"
     ]
    }
   ],
   "source": [
    "model = DKN(hparams, DKNTextIterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "signal-sleep",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 19:54:34.037273: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-22 19:54:34.039995: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.4765, 'group_auc': 0.4871, 'mean_mrr': 0.1596, 'ndcg@5': 0.1552, 'ndcg@10': 0.2091}\n"
     ]
    }
   ],
   "source": [
    "print(model.run_eval(valid_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_file, valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-thanks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-driving",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
